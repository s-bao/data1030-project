{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/oasis_longitudinal.csv')\n",
    "\n",
    "# drop Hand (since all R) and MRI ID\n",
    "df_cleaned = df.drop(columns=['Hand','MRI ID'])\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "X = df_cleaned.drop(columns = ['Group', 'Subject ID'])\n",
    "y = df_cleaned['Group']\n",
    "subject_ids = df_cleaned['Subject ID'] # groups (for group structure, not labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Features Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_ftrs_MLpipe_SGKFold_accuracy(X_train, Y_train, X_CV, y_CV, X_test, y_test, ):\n",
    "    '''\n",
    "    Reduced features model pipeline with:\n",
    "        Splitting method -- StratifiedGroupKFold\n",
    "        Evaluation metric -- accuracy\n",
    "    '''\n",
    "\n",
    "    # find all unique patterns of missing value in test set\n",
    "    mask = X_test.isnull()\n",
    "    unique_rows = np.array(np.unique(mask, axis=0))\n",
    "    all_y_test_pred = pd.DataFrame()\n",
    "    \n",
    "    print('there are', len(unique_rows), 'unique missing value patterns.')\n",
    "    \n",
    "    # divide test sets into subgroups according to the unique patterns\n",
    "    for i in range(len(unique_rows)):\n",
    "        print ('working on unique pattern', i)\n",
    "        ## generate X_test subset that matches the unique pattern i\n",
    "        sub_X_test = pd.DataFrame()\n",
    "        sub_y_test = pd.Series(dtype=float)\n",
    "        for j in range(len(mask)): # check each row in mask\n",
    "            row_mask = np.array(mask.iloc[j])\n",
    "            if np.array_equal(row_mask, unique_rows[i]): # if the pattern matches the ith unique pattern\n",
    "\n",
    "                sub_X_test = pd.concat([sub_X_test,X_test.iloc[[j]]])# append the according X_test row j to the subset\n",
    "                sub_y_test = pd.concat([sub_y_test, y_test.iloc[[j]]])# append the according y_test row j\n",
    "\n",
    "        sub_X_test = sub_X_test[X_test.columns[~unique_rows[i]]]\n",
    "        \n",
    "        ## choose the according reduced features for subgroups\n",
    "        sub_X_train = pd.DataFrame()\n",
    "        sub_Y_train = pd.DataFrame()\n",
    "        sub_X_CV = pd.DataFrame()\n",
    "        sub_y_CV = pd.DataFrame()\n",
    "        # 1.cut the feature columns that have nans in the according sub_X_test\n",
    "        sub_X_train = X_train[X_train.columns[~unique_rows[i]]]\n",
    "        sub_X_CV = X_CV[X_CV.columns[~unique_rows[i]]]\n",
    "        # 2.cut the rows in the sub_X_train and sub_X_CV that have any nans\n",
    "        sub_X_train = sub_X_train.dropna()\n",
    "        sub_X_CV = sub_X_CV.dropna()   \n",
    "        # 3.cut the sub_Y_train and sub_y_CV accordingly\n",
    "        sub_Y_train = Y_train.iloc[sub_X_train.index]\n",
    "        sub_y_CV = y_CV.iloc[sub_X_CV.index]\n",
    "        \n",
    "        # run XGB\n",
    "        sub_y_test_pred = xgb_model(sub_X_train, sub_Y_train, sub_X_CV, \n",
    "                                       sub_y_CV, sub_X_test, sub_y_test, verbose=0)\n",
    "        sub_y_test_pred = pd.DataFrame(sub_y_test_pred[1],columns=['sub_y_test_pred'],\n",
    "                                          index=sub_y_test.index)\n",
    "        print('   RMSE:',np.sqrt(mean_squared_error(sub_y_test,sub_y_test_pred)))\n",
    "        # collect the test predictions\n",
    "        all_y_test_pred = pd.concat([all_y_test_pred, sub_y_test_pred])\n",
    "        \n",
    "    # rank the final y_test_pred according to original y_test index\n",
    "    all_y_test_pred = all_y_test_pred.sort_index()\n",
    "    y_test = y_test.sort_index()\n",
    "               \n",
    "    # get global RMSE\n",
    "    total_RMSE = np.sqrt(mean_squared_error(y_test,all_y_test_pred))\n",
    "    total_R2 =  r2_score(y_test,all_y_test_pred)\n",
    "    return total_RMSE, total_R2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
