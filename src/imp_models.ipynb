{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Subject ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Age', 'EDUC', 'SES',\n",
      "       'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/oasis_longitudinal.csv')\n",
    "\n",
    "# drop Hand (since all R) and MRI ID\n",
    "df_cleaned = df.drop(columns=['Hand','MRI ID'])\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "X = df_cleaned.drop(columns = ['Group', 'Subject ID'])\n",
    "y = df_cleaned['Group']\n",
    "subject_ids = df_cleaned['Subject ID'] # groups (for group structure, not labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct preprocesser (code from eda notebook -- tested it there)\n",
    "# Decide which encoder to use on each feature\n",
    "minmax_ftrs = ['Age', 'MMSE', 'EDUC']\n",
    "onehot_ftrs = ['M/F']\n",
    "ordinal_ftrs = ['Visit', 'SES', 'CDR']\n",
    "ordinal_cats = [[1, 2, 3, 4, 5], [-1, 1.0, 2.0, 3.0, 4.0, 5.0], [0.0, 0.5, 1.0, 2.0]]\n",
    "std_ftrs = ['MR Delay', 'eTIV', 'nWBV', 'ASF']\n",
    "\n",
    "# Ordinal encoder (separate because need imputer for SES missing values)\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value=-1)),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# Collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('onehot', OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline w/ Multivariate Imputation ##\n",
    "After preprocessing, the only remaining variable with missing values is MMSE, and it only has 2 missing values. Since MMSE is the cognitive test score, I thought that it was reasonable to do multivariate imputation, especially considering how few missing values are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLpipe_imp_SGKFold(X, y, preprocessor, ML_algo, param_grid, model_name, eval_metric):\n",
    "    '''\n",
    "    Pipeline with:\n",
    "        Missing values handling method - Multivariate Imputation\n",
    "        Splitting method -- StratifiedGroupKFold\n",
    "        Evaluation metric -- Depends on input\n",
    "    '''\n",
    "\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    num_states = 10\n",
    "\n",
    "    for i in range(num_states):\n",
    "        # Define random state\n",
    "        random_state = 29*i\n",
    "        print(f\"---Running random state {random_state}---\")\n",
    "\n",
    "        # ---SPLIT---\n",
    "        outer_split = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=random_state) # Outer split: split test and other\n",
    "\n",
    "        for other_idx, test_idx in outer_split.split(X, y, groups=subject_ids):\n",
    "            break # Break after the first split to separate out the test set for this state\n",
    "        \n",
    "        # print(f\"\\n[Outer Split] Fold {i + 1}\")\n",
    "        # print(f\"Train+Validation size: {len(other_idx)}, Test size: {len(test_idx)}\")\n",
    "        # print(f\"Train+Validation percentage: {len(other_idx) / len(X) * 100:.2f}%, Test percentage: {len(test_idx) / len(X) * 100:.2f}%\")\n",
    "        # print(f\"Groups in Train+Validation: {pd.Series(subject_ids.iloc[other_idx]).nunique()}, Groups in Test: {pd.Series(subject_ids.iloc[test_idx]).nunique()}\")\n",
    "\n",
    "        X_other = X.iloc[other_idx]\n",
    "        y_other = y.iloc[other_idx]\n",
    "        subject_ids_other = subject_ids.iloc[other_idx] \n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        kf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=random_state) # Inner split: 4 fold CV\n",
    "\n",
    "        # ---PREPROCESS---\n",
    "        # Main preprocessor is fed into function in \"preprocessor\"\n",
    "        final_scaler = StandardScaler()\n",
    "\n",
    "        # ---IMPUTE---\n",
    "        imputer = IterativeImputer(estimator = RandomForestRegressor(n_estimators=1), random_state=random_state, max_iter=1000000)\n",
    "\n",
    "        # ---CONSTRUCT PIPELINE & GRID SEARCH---\n",
    "        pipeline = make_pipeline(preprocessor, imputer, final_scaler, ML_algo)\n",
    "\n",
    "        if eval_metric == \"accuracy\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='accuracy', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"precision\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='precision_macro', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"f1_macro\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='f1_macro', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"f1_weighted\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='f1_weighted', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        else:\n",
    "            raise ValueError(\"Evaluation metric not handled in this pipeline.\")\n",
    "        \n",
    "        grid.fit(X_other, y_other, groups=subject_ids_other)\n",
    "\n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        # print(\"\\nGrid search results:\\n\", results)\n",
    "\n",
    "        # ---SAVE BEST MODEL PER RANDOM STATE PER MODEL---\n",
    "        best_model = grid.best_estimator_\n",
    "        best_models.append(best_model)\n",
    "        print('Best model parameters:', grid.best_params_)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        if eval_metric == \"accuracy\":\n",
    "            best_test_score = accuracy_score(y_test, y_test_pred)\n",
    "        elif eval_metric == \"precision\":\n",
    "            best_test_score = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "        elif eval_metric == \"f1_macro\":\n",
    "            best_test_score = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "        elif eval_metric == \"f1_weighted\":\n",
    "            best_test_score = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "        else:\n",
    "            raise ValueError(\"Evaluation metric not handled in this pipeline.\")\n",
    "            \n",
    "        test_scores.append(best_test_score)\n",
    "        print(f\"Test score for random state {29*i}: {best_test_score:.4f}\")\n",
    "        \n",
    "    # ---SAVE ALL BEST MODELS AND TEST SCORES PER MODEL IN RESULTS---\n",
    "    file_path = os.path.join('../results/', f'{model_name}_{eval_metric}_results.save')\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump((best_models, test_scores), file)\n",
    "\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.8750\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.9605\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.9359\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.8676\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.9333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.8718\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.8904\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Test pipeline on simple logistic regression model first\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=100000000)\n",
    "param_grid = {} \n",
    "log_reg_test_scores, log_reg_best_models = MLpipe_imp_SGKFold(X, y, preprocessor, log_reg, param_grid, \"Test_SimpleLogisticRegression\", \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model algorithms and parameter grids\n",
    "models = {\n",
    "    'SimpleLogisticRegression': (\n",
    "        LogisticRegression(solver='saga', max_iter=1000000), {} \n",
    "    ),\n",
    "    'L1LogisticRegression': (\n",
    "        LogisticRegression(penalty='l1', solver='saga', max_iter=1000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    ),\n",
    "    'L2LogisticRegression': (\n",
    "        LogisticRegression(penalty='l2', solver='saga', max_iter=1000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    ),\n",
    "    'ElasticNet': (\n",
    "        LogisticRegression(penalty='elasticnet', solver='saga', max_iter=100000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "         'logisticregression__l1_ratio': [0.001, 0.01, 0.1, 1]}\n",
    "    ),\n",
    "    'RandomForestClassifier': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'randomforestclassifier__n_estimators': [100],\n",
    "         'randomforestclassifier__max_depth': [1, 3, 5, 10, 20, 100],\n",
    "         'randomforestclassifier__max_features': [0.25, 0.5, 0.75, 1.0, None]}\n",
    "    ),\n",
    "    'SupportVectorClassifier': (\n",
    "        SVC(probability=True),\n",
    "        {'svc__C': [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "         'svc__gamma': [1e-5, 1e-3, 1e-1, 1e1, 1e3, 1e5]}\n",
    "    ),\n",
    "    'KNeighborsClassifier': (\n",
    "        KNeighborsClassifier(),\n",
    "        {'kneighborsclassifier__n_neighbors': [3, 5, 10, 20],\n",
    "         'kneighborsclassifier__weights': ['uniform', 'distance']}\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleLogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.8750\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.9605\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.9359\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.8676\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.9333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.8718\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.8904\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.9167\n",
      "Test Accuracy Scores: [0.9, 0.875, 0.9605263157894737, 0.9358974358974359, 0.8676470588235294, 0.948051948051948, 0.9333333333333333, 0.8717948717948718, 0.8904109589041096, 0.9166666666666666]\n",
      "Mean Test Accuracy: 0.9099\n",
      "Std Dev of Test Accuracy: 0.0320\n",
      "\n",
      "Training L1LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 29: 0.8611\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 58: 0.9868\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 87: 0.9231\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 116: 0.8529\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 174: 0.9200\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 203: 0.8846\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 232: 0.8630\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 261: 0.9028\n",
      "Test Accuracy Scores: [0.9, 0.8611111111111112, 0.9868421052631579, 0.9230769230769231, 0.8529411764705882, 0.948051948051948, 0.92, 0.8846153846153846, 0.863013698630137, 0.9027777777777778]\n",
      "Mean Test Accuracy: 0.9042\n",
      "Std Dev of Test Accuracy: 0.0399\n",
      "\n",
      "Training L2LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 29: 0.8750\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 58: 0.9868\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 87: 0.9231\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 116: 0.8529\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 174: 0.9333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 203: 0.8718\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 232: 0.8767\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 261: 0.9167\n",
      "Test Accuracy Scores: [0.9, 0.875, 0.9868421052631579, 0.9230769230769231, 0.8529411764705882, 0.948051948051948, 0.9333333333333333, 0.8717948717948718, 0.8767123287671232, 0.9166666666666666]\n",
      "Mean Test Accuracy: 0.9084\n",
      "Std Dev of Test Accuracy: 0.0390\n",
      "\n",
      "Training ElasticNet...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 29: 0.8750\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 58: 0.9868\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 87: 0.9231\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.1}\n",
      "Test score for random state 116: 0.8529\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 174: 0.9200\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.1}\n",
      "Test score for random state 203: 0.8846\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.1}\n",
      "Test score for random state 232: 0.8767\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.1}\n",
      "Test score for random state 261: 0.9167\n",
      "Test Accuracy Scores: [0.9, 0.875, 0.9868421052631579, 0.9230769230769231, 0.8529411764705882, 0.948051948051948, 0.92, 0.8846153846153846, 0.8767123287671232, 0.9166666666666666]\n",
      "Mean Test Accuracy: 0.9084\n",
      "Std Dev of Test Accuracy: 0.0374\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 29: 0.8611\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 58: 0.9737\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 87: 0.9231\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 116: 0.8529\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 145: 0.9610\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 174: 0.9200\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 203: 0.8846\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 232: 0.8630\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 261: 0.9028\n",
      "Test Accuracy Scores: [0.9, 0.8611111111111112, 0.9736842105263158, 0.9230769230769231, 0.8529411764705882, 0.961038961038961, 0.92, 0.8846153846153846, 0.863013698630137, 0.9027777777777778]\n",
      "Mean Test Accuracy: 0.9042\n",
      "Std Dev of Test Accuracy: 0.0390\n",
      "\n",
      "Training SupportVectorClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 0: 0.9000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 29: 0.8750\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 58: 0.9868\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 87: 0.9231\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 116: 0.8971\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 145: 0.9481\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 174: 0.9200\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 203: 0.8846\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 232: 0.8630\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 261: 0.8889\n",
      "Test Accuracy Scores: [0.9, 0.875, 0.9868421052631579, 0.9230769230769231, 0.8970588235294118, 0.948051948051948, 0.92, 0.8846153846153846, 0.863013698630137, 0.8888888888888888]\n",
      "Mean Test Accuracy: 0.9087\n",
      "Std Dev of Test Accuracy: 0.0352\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 0: 0.8000\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 29: 0.8611\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 58: 0.9474\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 87: 0.8590\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 116: 0.7500\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 145: 0.9091\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 174: 0.9200\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 203: 0.8462\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 232: 0.8493\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 261: 0.6944\n",
      "Test Accuracy Scores: [0.8, 0.8611111111111112, 0.9473684210526315, 0.8589743589743589, 0.75, 0.9090909090909091, 0.92, 0.8461538461538461, 0.8493150684931506, 0.6944444444444444]\n",
      "Mean Test Accuracy: 0.8436\n",
      "Std Dev of Test Accuracy: 0.0737\n",
      "\n",
      "Summary of Results:\n",
      "SimpleLogisticRegression: Mean Accuracy = 0.9099, Std Dev = 0.0320\n",
      "L1LogisticRegression: Mean Accuracy = 0.9042, Std Dev = 0.0399\n",
      "L2LogisticRegression: Mean Accuracy = 0.9084, Std Dev = 0.0390\n",
      "ElasticNet: Mean Accuracy = 0.9084, Std Dev = 0.0374\n",
      "RandomForestClassifier: Mean Accuracy = 0.9042, Std Dev = 0.0390\n",
      "SupportVectorClassifier: Mean Accuracy = 0.9087, Std Dev = 0.0352\n",
      "KNeighborsClassifier: Mean Accuracy = 0.8436, Std Dev = 0.0737\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric = accuracy\n",
    "summary = {}\n",
    "for model_name, (algo, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    test_scores, best_models = MLpipe_imp_SGKFold(X, y, preprocessor, algo, param_grid, model_name, \"accuracy\")\n",
    "    mean_score = np.mean(test_scores)\n",
    "    stddev_score = np.std(test_scores)\n",
    "    print(\"Test Accuracy Scores:\", test_scores)\n",
    "    print(f\"Mean Test Accuracy: {mean_score:.4f}\")\n",
    "    print(f\"Std Dev of Test Accuracy: {stddev_score:.4f}\")\n",
    "    summary[model_name] = (mean_score, stddev_score)\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nSummary of Results:\")\n",
    "for model_name, (mean_score, stddev_score) in summary.items():\n",
    "    print(f\"{model_name}: Mean Accuracy = {mean_score:.4f}, Std Dev = {stddev_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleLogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.6264\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.7556\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.6479\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.7500\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.7522\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.6382\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.7508\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.6743\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.7380\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.7697\n",
      "Test f1 Scores: [0.6264264264264264, 0.7556418973611786, 0.6479260369815093, 0.7500476462740613, 0.7521741939652387, 0.6381551362683439, 0.7507936507936508, 0.6743055555555556, 0.7379679144385026, 0.7697175141242938]\n",
      "Mean Test f1: 0.7103\n",
      "Std Dev of Test f1: 0.0536\n",
      "\n",
      "Training L1LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 0: 0.6264\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 29: 0.6938\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 58: 0.6442\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 87: 0.7500\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 116: 0.7009\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.6382\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 174: 0.7508\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 203: 0.7403\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 232: 0.7380\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 261: 0.7411\n",
      "Test f1 Scores: [0.6264264264264264, 0.6938375350140057, 0.6441834028040925, 0.7500476462740613, 0.7008928571428571, 0.6381551362683439, 0.7507936507936508, 0.7402777777777777, 0.7379679144385026, 0.7410951621477936]\n",
      "Mean Test f1: 0.7024\n",
      "Std Dev of Test f1: 0.0471\n",
      "\n",
      "Training L2LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 0: 0.6264\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 29: 0.7159\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 58: 0.6442\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 87: 0.7500\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 116: 0.7044\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.6382\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 174: 0.7291\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 203: 0.7261\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 232: 0.7380\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 261: 0.7411\n",
      "Test f1 Scores: [0.6264264264264264, 0.7158730158730159, 0.6441834028040925, 0.7500476462740613, 0.7044225146198829, 0.6381551362683439, 0.7290825934893732, 0.7261090761090762, 0.7379679144385026, 0.7410951621477936]\n",
      "Mean Test f1: 0.7013\n",
      "Std Dev of Test f1: 0.0445\n",
      "\n",
      "Training ElasticNet...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 0: 0.6264\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 29: 0.7159\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 58: 0.6442\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 87: 0.7500\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 116: 0.7009\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 145: 0.6382\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 174: 0.7508\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 203: 0.7403\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 232: 0.7380\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 261: 0.7411\n",
      "Test f1 Scores: [0.6264264264264264, 0.7158730158730159, 0.6441834028040925, 0.7500476462740613, 0.7008928571428571, 0.6381551362683439, 0.7507936507936508, 0.7402777777777777, 0.7379679144385026, 0.7410951621477936]\n",
      "Mean Test f1: 0.7046\n",
      "Std Dev of Test f1: 0.0472\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 0: 0.6950\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 29: 0.6997\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 58: 0.6324\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 100, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 87: 0.6319\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 116: 0.7636\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 145: 0.6459\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 174: 0.6344\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 203: 0.7714\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 232: 0.7380\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 261: 0.7709\n",
      "Test f1 Scores: [0.6950443401147627, 0.6997032000431709, 0.6324451410658307, 0.6318658280922432, 0.7635845150201179, 0.6458846048673776, 0.6344002081707, 0.7713517665130567, 0.7379679144385026, 0.7708708708708709]\n",
      "Mean Test f1: 0.6983\n",
      "Std Dev of Test f1: 0.0566\n",
      "\n",
      "Training SupportVectorClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 0: 0.7093\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 29: 0.7547\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 58: 0.9861\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 87: 0.7261\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 116: 0.7795\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 145: 0.6382\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 174: 0.7508\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 203: 0.7403\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 232: 0.6829\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.1}\n",
      "Test score for random state 261: 0.5750\n",
      "Test f1 Scores: [0.7092592592592593, 0.7546783625730994, 0.9861490796427921, 0.7260703315990723, 0.7795424701085079, 0.6381551362683439, 0.7507936507936508, 0.7402777777777777, 0.6829161176987264, 0.5750237416904084]\n",
      "Mean Test f1: 0.7343\n",
      "Std Dev of Test f1: 0.1021\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 0: 0.5914\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 29: 0.6747\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 58: 0.6346\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 87: 0.7013\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 116: 0.5826\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 145: 0.5907\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 174: 0.6573\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 203: 0.6068\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 232: 0.6642\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 261: 0.5201\n",
      "Test f1 Scores: [0.5914367556158601, 0.6746919333126229, 0.6346300533943555, 0.7013366750208855, 0.5826383284010402, 0.5906542056074766, 0.6572649572649573, 0.6068239370918299, 0.6641858728126334, 0.5201067768879704]\n",
      "Mean Test f1: 0.6224\n",
      "Std Dev of Test f1: 0.0513\n",
      "\n",
      "Summary of Results:\n",
      "SimpleLogisticRegression: Mean f1 = 0.7103, Std Dev = 0.0536\n",
      "L1LogisticRegression: Mean f1 = 0.7024, Std Dev = 0.0471\n",
      "L2LogisticRegression: Mean f1 = 0.7013, Std Dev = 0.0445\n",
      "ElasticNet: Mean f1 = 0.7046, Std Dev = 0.0472\n",
      "RandomForestClassifier: Mean f1 = 0.6983, Std Dev = 0.0566\n",
      "SupportVectorClassifier: Mean f1 = 0.7343, Std Dev = 0.1021\n",
      "KNeighborsClassifier: Mean f1 = 0.6224, Std Dev = 0.0513\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric = f1 macro\n",
    "summary = {}\n",
    "for model_name, (algo, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    test_scores, best_models = MLpipe_imp_SGKFold(X, y, preprocessor, algo, param_grid, model_name, \"f1_macro\")\n",
    "    mean_score = np.mean(test_scores)\n",
    "    stddev_score = np.std(test_scores)\n",
    "    print(\"Test f1 Scores:\", test_scores)\n",
    "    print(f\"Mean Test f1: {mean_score:.4f}\")\n",
    "    print(f\"Std Dev of Test f1: {stddev_score:.4f}\")\n",
    "    summary[model_name] = (mean_score, stddev_score)\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nSummary of Results:\")\n",
    "for model_name, (mean_score, stddev_score) in summary.items():\n",
    "    print(f\"{model_name}: Mean f1 = {mean_score:.4f}, Std Dev = {stddev_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleLogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.8596\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.8576\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.9734\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.9199\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.8487\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.9420\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.9166\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.8422\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.8572\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.9012\n",
      "Test f1 Scores: [0.8596396396396396, 0.8575899843505478, 0.9733981693363845, 0.9198699623227926, 0.8486585407568726, 0.9419913419913419, 0.9166349206349207, 0.842227564102564, 0.8571533221009451, 0.9011864406779662]\n",
      "Mean Test f1: 0.8918\n",
      "Std Dev of Test f1: 0.0429\n",
      "\n",
      "Training L1LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 0: 0.8596\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 29: 0.8686\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 58: 0.9665\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 87: 0.9199\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 116: 0.8473\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.9420\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 174: 0.9166\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 203: 0.8507\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 232: 0.8572\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 261: 0.8765\n",
      "Test f1 Scores: [0.8596396396396396, 0.8685515873015873, 0.9664545980335455, 0.9198699623227926, 0.8473389355742297, 0.9419913419913419, 0.9166349206349207, 0.8506634391249778, 0.8571533221009451, 0.8764841396420343]\n",
      "Mean Test f1: 0.8905\n",
      "Std Dev of Test f1: 0.0402\n",
      "\n",
      "Training L2LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 0: 0.8596\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 29: 0.8576\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 58: 0.9665\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 87: 0.9199\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 116: 0.8487\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 145: 0.9420\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 174: 0.9166\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 203: 0.8422\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 232: 0.8572\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 261: 0.8765\n",
      "Test f1 Scores: [0.8596396396396396, 0.8575899843505478, 0.9664545980335455, 0.9198699623227926, 0.8486585407568726, 0.9419913419913419, 0.9166349206349207, 0.842227564102564, 0.8571533221009451, 0.8764841396420343]\n",
      "Mean Test f1: 0.8887\n",
      "Std Dev of Test f1: 0.0417\n",
      "\n",
      "Training ElasticNet...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 0: 0.8596\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 29: 0.8576\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 0.01}\n",
      "Test score for random state 58: 0.9665\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 87: 0.9199\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 116: 0.8473\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 145: 0.9420\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 174: 0.9166\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 203: 0.8422\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 232: 0.8572\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 261: 0.8765\n",
      "Test f1 Scores: [0.8596396396396396, 0.8575899843505478, 0.9664545980335455, 0.9198699623227926, 0.8473389355742297, 0.9419913419913419, 0.9166349206349207, 0.842227564102564, 0.8571533221009451, 0.8764841396420343]\n",
      "Mean Test f1: 0.8885\n",
      "Std Dev of Test f1: 0.0418\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 0: 0.8803\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 29: 0.8252\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 58: 0.9734\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 87: 0.8928\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 116: 0.8186\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 145: 0.9486\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 174: 0.8883\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 1.0, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 203: 0.8841\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 232: 0.8572\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 261: 0.8568\n",
      "Test f1 Scores: [0.8803174603174603, 0.8251825769431403, 0.9733981693363845, 0.8927914852443155, 0.8186050292043633, 0.9486166007905138, 0.8882851938589643, 0.884065934065934, 0.8571533221009451, 0.8567921146953404]\n",
      "Mean Test f1: 0.8825\n",
      "Std Dev of Test f1: 0.0463\n",
      "\n",
      "Training SupportVectorClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 0: 0.8803\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 29: 0.8573\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 58: 0.9733\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 87: 0.9103\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 116: 0.8732\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 145: 0.9420\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 174: 0.9166\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 203: 0.8739\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 232: 0.8304\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 261: 0.8878\n",
      "Test f1 Scores: [0.8803174603174603, 0.8572733918128654, 0.9732672087689511, 0.9102716794686956, 0.873232427949409, 0.9419913419913419, 0.9166349206349207, 0.873878205128205, 0.8304185391737506, 0.8878282828282829]\n",
      "Mean Test f1: 0.8945\n",
      "Std Dev of Test f1: 0.0398\n",
      "\n",
      "Training KNeighborsClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 0: 0.8118\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 29: 0.8208\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 58: 0.9324\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 20, 'kneighborsclassifier__weights': 'distance'}\n",
      "Test score for random state 87: 0.8281\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 116: 0.7089\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 145: 0.8976\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 174: 0.8486\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 203: 0.8045\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 10, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 232: 0.8067\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Best model parameters: {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__weights': 'uniform'}\n",
      "Test score for random state 261: 0.7048\n",
      "Test f1 Scores: [0.8118304580991148, 0.8208208208208209, 0.9324125531219354, 0.8280501549732319, 0.7088812926300463, 0.897584658332322, 0.8485811965811966, 0.8045089656445115, 0.8066932103204532, 0.7047633399351301]\n",
      "Mean Test f1: 0.8164\n",
      "Std Dev of Test f1: 0.0675\n",
      "\n",
      "Summary of Results:\n",
      "SimpleLogisticRegression: Mean f1 = 0.8918, Std Dev = 0.0429\n",
      "L1LogisticRegression: Mean f1 = 0.8905, Std Dev = 0.0402\n",
      "L2LogisticRegression: Mean f1 = 0.8887, Std Dev = 0.0417\n",
      "ElasticNet: Mean f1 = 0.8885, Std Dev = 0.0418\n",
      "RandomForestClassifier: Mean f1 = 0.8825, Std Dev = 0.0463\n",
      "SupportVectorClassifier: Mean f1 = 0.8945, Std Dev = 0.0398\n",
      "KNeighborsClassifier: Mean f1 = 0.8164, Std Dev = 0.0675\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metric = f1 weighted\n",
    "summary = {}\n",
    "for model_name, (algo, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    test_scores, best_models = MLpipe_imp_SGKFold(X, y, preprocessor, algo, param_grid, model_name, \"f1_weighted\")\n",
    "    mean_score = np.mean(test_scores)\n",
    "    stddev_score = np.std(test_scores)\n",
    "    print(\"Test f1 Scores:\", test_scores)\n",
    "    print(f\"Mean Test f1: {mean_score:.4f}\")\n",
    "    print(f\"Std Dev of Test f1: {stddev_score:.4f}\")\n",
    "    summary[model_name] = (mean_score, stddev_score)\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nSummary of Results:\")\n",
    "for model_name, (mean_score, stddev_score) in summary.items():\n",
    "    print(f\"{model_name}: Mean f1 = {mean_score:.4f}, Std Dev = {stddev_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
